{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "EEG_classificator_custom.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNelvQQ9WlH+YRhWOhdr8lf",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Gooogr/Brain2Image/blob/master/sub_notebooks/EEG_classificator_custom.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FQYla7FxIgqm",
        "colab_type": "text"
      },
      "source": [
        "EEG signals classificator based on Perceive Lab dataset<br>\n",
        "Dataset:  http://www.perceivelab.com/dataset/EEG%20Data%20for%20Visual%20Classification"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oX3L1XUaV6mC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Imports\n",
        "import sys\n",
        "import os\n",
        "import random\n",
        "import math\n",
        "import time\n",
        "import torch; torch.utils.backcompat.broadcast_warning.enabled = True\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision import transforms, datasets\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim\n",
        "import torch.backends.cudnn as cudnn; cudnn.benchmark = True\n",
        "from scipy.fftpack import fft, rfft, fftfreq, irfft, ifft, rfftfreq\n",
        "import numpy as np"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yg9R-CwVSY4_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount(\"/content/drive\", force_remount=True)\n",
        "! ln -s \"/content/drive/My Drive\" \"/content/mydrive\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "50LeCBPHIa0X",
        "colab_type": "text"
      },
      "source": [
        "Link to code:<br>\n",
        "https://arxiv.org/pdf/1812.07697.pdf\n",
        "\n",
        "Link to percivelab files:<br>\n",
        "http://perceive.dieei.unict.it/files/\n",
        "\n",
        "Link to LSTM script from the article:<br>\n",
        "http://perceive.dieei.unict.it/files/cvpr_2017_eeg_encoder.py"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ctm2akwZWlkI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# # Define options\n",
        "# import argparse\n",
        "# parser = argparse.ArgumentParser(description=\"Template\")\n",
        "# # Dataset options\n",
        "# parser.add_argument('-ed', '--eeg-dataset', default=\"datasets/eeg_signals_band_all.pth\", help=\"EEG dataset path\")\n",
        "# parser.add_argument('-sp', '--splits-path', default=\"datasets/splits_by_image.pth\", help=\"splits path\")\n",
        "# parser.add_argument('-sn', '--split-num', default=0, type=int, help=\"split number\")\n",
        "# # Model options\n",
        "# parser.add_argument('-ll', '--lstm-layers', default=1, type=int, help=\"LSTM layers\")\n",
        "# parser.add_argument('-ls', '--lstm-size', default=128, type=int, help=\"LSTM hidden size\")\n",
        "# parser.add_argument('-es', '--embedding-size', default=128, type=int, help=\"embedding size\")\n",
        "# parser.add_argument('-nc', '--num-classes', default=40, type=int, help=\"num classes\")\n",
        "\n",
        "# # Filtering options\n",
        "# parser.add_argument('-filt', '--filtering', default=True,  help=\"filter your data\")\n",
        "\n",
        "# # Training options\n",
        "# parser.add_argument(\"-b\", \"--batch_size\", default=16, type=int, help=\"batch size\")\n",
        "# parser.add_argument('-o', '--optim', default=\"Adam\", help=\"optimizer\")\n",
        "# parser.add_argument('-lr', '--learning-rate', default=0.001, type=float, help=\"learning rate\")\n",
        "# parser.add_argument('-lrdb', '--learning-rate-decay-by', default=0.5, type=float, help=\"learning rate decay factor\")\n",
        "# parser.add_argument('-lrde', '--learning-rate-decay-every', default=10, type=int, help=\"learning rate decay period\")\n",
        "# parser.add_argument('-e', '--epochs', default=300, type=int, help=\"training epochs\")\n",
        "# parser.add_argument('-dw', '--data-workers', default=16, type=int, help=\"data loading workers\")\n",
        "# # Backend options\n",
        "# parser.add_argument('--no-cuda', default=False, help=\"disable CUDA\", action=\"store_true\")\n",
        "\n",
        "# # Parse arguments\n",
        "# opt = parser.parse_args()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_MY4GxCIIdPa",
        "colab_type": "text"
      },
      "source": [
        "### Prepare dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_KH7owS9J6xs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "DATASET_PATH = '/content/mydrive/EEG2Image_research/Datasets/perceive_lab/eeg_signals_128_sequential_band_all_with_mean_std.pth'\n",
        "SPLIT_PATH = '/content/mydrive/EEG2Image_research/Datasets/perceive_lab/block_splits_by_image.pth'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qHfYYBKsSd__",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# !python3 cvpr_2017_eeg_encoder.py -ed $DATASET_PATH -sp $SPLIT_PATH"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4Fo99DqxWJq9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Dataset class\n",
        "class EEGDataset:\n",
        "    \n",
        "    # Constructor\n",
        "    def __init__(self, eeg_signals_path):\n",
        "        # Load EEG signals\n",
        "        loaded = torch.load(eeg_signals_path)\n",
        "        self.data = loaded[\"dataset\"]\n",
        "        self.labels = loaded[\"labels\"]\n",
        "        self.images = loaded[\"images\"]\n",
        "        self.means = loaded[\"means\"]\n",
        "        self.stddevs = loaded[\"stddevs\"]\n",
        "        # Compute size\n",
        "        self.size = len(self.data)\n",
        "\n",
        "    # Get size\n",
        "    def __len__(self):\n",
        "        return self.size\n",
        "\n",
        "    # Get item\n",
        "    def __getitem__(self, i):\n",
        "        # Process EEG\n",
        "        eeg = ((self.data[i][\"eeg\"].float() - self.means)/self.stddevs) #.t() # CxT\n",
        "        # Check filtering\n",
        "        # Uses global opt\n",
        "        if opt.filtering:\n",
        "            # Time axis\n",
        "            N = eeg.size(1)\n",
        "            T = 1.0/1000.0\n",
        "            time = np.linspace(0.0, N*T, N)\n",
        "            # Frequency axis\n",
        "            w = rfftfreq(N, T)\n",
        "            # FFT\n",
        "            eeg = eeg.numpy()\n",
        "            eeg_fft = rfft(eeg)\n",
        "            # Filter\n",
        "            eeg_fft[:,w < 15] = 0\n",
        "            eeg_fft[:,np.bitwise_and(w > 47, w < 53)] = 0\n",
        "            eeg_fft[:,w > 71] = 0\n",
        "            eeg = irfft(eeg_fft)\n",
        "            # Convert to tensor\n",
        "            eeg = torch.tensor(eeg)\n",
        "        # Transpose to TxC\n",
        "        eeg = eeg.t()\n",
        "        eeg = eeg[20:460,:]\n",
        "        # Get label\n",
        "        label = self.data[i][\"label\"]\n",
        "        # Return\n",
        "        return eeg, label\n",
        "\n",
        "# Splitter class\n",
        "class Splitter:\n",
        "\n",
        "    def __init__(self, dataset, split_path, split_num=0, split_name=\"train\"):\n",
        "        # Set EEG dataset\n",
        "        self.dataset = dataset\n",
        "        # Load split\n",
        "        loaded = torch.load(split_path)\n",
        "        self.split_idx = loaded[\"splits\"][split_num][split_name]\n",
        "        # Filter data\n",
        "        self.split_idx = [i for i in self.split_idx if 450 <= self.dataset.data[i][\"eeg\"].size(1) <= 600]\n",
        "        # Compute size\n",
        "        self.size = len(self.split_idx)\n",
        "\n",
        "    # Get size\n",
        "    def __len__(self):\n",
        "        return self.size\n",
        "\n",
        "    # Get item\n",
        "    def __getitem__(self, i):\n",
        "        # Get sample from dataset\n",
        "        eeg, label = self.dataset[self.split_idx[i]]\n",
        "        # Return\n",
        "        return eeg, label"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NN2-Mg2UWU01",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Load dataset\n",
        "dataset = EEGDataset(opt.eeg_dataset)\n",
        "# Create loaders\n",
        "loaders = {split: DataLoader(Splitter(dataset, split_path = opt.splits_path, split_num = opt.split_num, split_name = split), batch_size = opt.batch_size, drop_last = True, shuffle = True) for split in [\"train\", \"val\", \"test\"]}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9a-H1F3HWyRz",
        "colab_type": "text"
      },
      "source": [
        "### Setting up model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FjvHvccXW8d1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Define model\n",
        "class Model(nn.Module):\n",
        "\n",
        "    def __init__(self, input_size, lstm_size, lstm_layers, embedding_size, num_classes):\n",
        "        # Call parent\n",
        "        super().__init__()\n",
        "        # Define parameters\n",
        "        self.input_size = input_size\n",
        "        self.lstm_size = lstm_size\n",
        "        self.lstm_layers = lstm_layers\n",
        "        self.embedding_size = embedding_size\n",
        "        self.num_classes = num_classes\n",
        "        # Define internal modules\n",
        "        self.lstm = nn.LSTM(input_size, lstm_size, num_layers=lstm_layers, batch_first=True)\n",
        "        self.embedding = nn.Linear(lstm_size, embedding_size)\n",
        "        self.classifier = nn.Linear(embedding_size, num_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Prepare LSTM initiale state\n",
        "        batch_size = x.size(0)\n",
        "        # Forward LSTM and get final state\n",
        "        x = self.lstm(x)[0][:,-1,:]\n",
        "        # Forward embedding\n",
        "        x = F.relu(self.embedding(x))\n",
        "        # Forward classifier\n",
        "        x = self.classifier(x)\n",
        "        return x"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y187PsYJW_pc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = Model(128, opt.lstm_size, opt.lstm_layers, opt.embedding_size, opt.num_classes)\n",
        "optimizer = getattr(torch.optim, opt.optim)(model.parameters(), lr = opt.learning_rate)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K97_08WDVziW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Setup CUDA\n",
        "if not opt.no_cuda:\n",
        "    model.cuda()\n",
        "    print(\"Copied to CUDA\")\n",
        "\n",
        "# Start training\n",
        "for epoch in range(1, opt.epochs+1):\n",
        "    # Initialize loss/accuracy variables\n",
        "    losses = {\"train\": 0, \"val\": 0, \"test\": 0}\n",
        "    accuracies = {\"train\": 0, \"val\": 0, \"test\": 0}\n",
        "    counts = {\"train\": 0, \"val\": 0, \"test\": 0}\n",
        "    # Adjust learning rate for SGD\n",
        "    if opt.optim == \"SGD\":\n",
        "        lr = opt.learning_rate * (opt.learning_rate_decay_by ** (epoch // opt.learning_rate_decay_every))\n",
        "        for param_group in optimizer.param_groups:\n",
        "            param_group['lr'] = lr\n",
        "    # Process each split\n",
        "    for split in (\"train\", \"val\", \"test\"):\n",
        "        # Set network mode\n",
        "        if split == \"train\":\n",
        "            model.train()\n",
        "            torch.set_grad_enabled(True)\n",
        "        else:\n",
        "            model.eval()\n",
        "            torch.set_grad_enabled(False)\n",
        "        # Process all split batches\n",
        "        for i, (input, target) in enumerate(loaders[split]):\n",
        "            # Check CUDA\n",
        "            if not opt.no_cuda:\n",
        "                input = input.cuda(async = True)\n",
        "                target = target.cuda(async = True)\n",
        "            # Forward\n",
        "            output = model(input)\n",
        "            loss = F.cross_entropy(output, target)\n",
        "            losses[split] += loss.item()\n",
        "            # Compute accuracy\n",
        "            _,pred = output.data.max(1)\n",
        "            correct = pred.eq(target.data).sum().item()\n",
        "            accuracy = correct/input.data.size(0)\n",
        "            accuracies[split] += accuracy\n",
        "            counts[split] += 1\n",
        "            # Backward and optimize\n",
        "            if split == \"train\":\n",
        "                optimizer.zero_grad()\n",
        "                loss.backward()\n",
        "                optimizer.step()\n",
        "    # Print info at the end of the epoch\n",
        "    print(\"Epoch {0}: TrL={1:.4f}, TrA={2:.4f}, VL={3:.4f}, VA={4:.4f}, TeL={5:.4f}, TeA={6:.4f}\".format(epoch,\n",
        "                                                                                                         losses[\"train\"]/counts[\"train\"],\n",
        "                                                                                                         accuracies[\"train\"]/counts[\"train\"],\n",
        "                                                                                                         losses[\"val\"]/counts[\"val\"],\n",
        "                                                                                                         accuracies[\"val\"]/counts[\"val\"],\n",
        "                                                                                                         losses[\"test\"]/counts[\"test\"],\n",
        "                                                                                                         accuracies[\"test\"]/counts[\"test\"]))\n"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}